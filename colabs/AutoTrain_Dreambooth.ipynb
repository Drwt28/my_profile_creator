{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drwt28/my_profile_creator/blob/main/colabs/AutoTrain_Dreambooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JvMRbVLEJlZT",
        "outputId": "f6172c34-b250-4f60-a73e-77b14d6468ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m> \u001b[1mINFO    Installing latest transformers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest transformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest peft@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest peft\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest diffusers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest diffusers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest trl@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest trl\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title ðŸ¤— AutoTrain DreamBooth\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - upload images to a folder named `images/`\n",
        "#@markdown - choose a project name if you wish\n",
        "#@markdown - change model if you wish, you can also select sd2/2.1 or sd1.5\n",
        "#@markdown - update prompt and remember it. choose keywords that don't usually appear in dictionaries\n",
        "#@markdown - add huggingface information (token and repo_id) if you wish to push trained model to huggingface hub\n",
        "#@markdown - update hyperparameters if you wish\n",
        "#@markdown - click `Runtime > Run all` or run each cell individually\n",
        "\n",
        "import os\n",
        "!pip install -U autotrain-advanced > install_logs.txt\n",
        "!autotrain setup > setup_logs.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mV3q-FZcD7vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "A2-_lkBS1WKA"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'my_profile_creater' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'photo of DR' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"hf_XXX\" #@param {type:\"string\"}\n",
        "repo_id = \"username/repo_name\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_fp16 = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "gradient_checkpointing = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"REPO_ID\"] = repo_id\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"USE_FP16\"] = str(use_fp16)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"GRADIENT_CHECKPOINTING\"] = str(gradient_checkpointing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g3cd_ED_yXXt",
        "outputId": "a11f0074-1d54-4155-a6a3-ba7611c9a80b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Namespace(version=False, model='stabilityai/stable-diffusion-xl-base-1.0', revision=None, tokenizer=None, image_path='images/', class_image_path=None, prompt='photo of DR', class_prompt=None, num_class_images=100, class_labels_conditioning=None, prior_preservation=None, prior_loss_weight=1.0, project_name='my_profile_creater', seed=42, resolution=1024, center_crop=None, train_text_encoder=None, batch_size=1, sample_batch_size=4, epochs=1, num_steps=500, checkpointing_steps=100000, resume_from_checkpoint=None, gradient_accumulation=4, gradient_checkpointing=True, lr=0.0001, scale_lr=None, scheduler='constant', warmup_steps=0, num_cycles=1, lr_power=1.0, dataloader_num_workers=0, use_8bit_adam=True, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, allow_tf32=None, prior_generation_precision=None, local_rank=-1, xformers=True, pre_compute_text_embeddings=None, tokenizer_max_length=None, text_encoder_use_attention_mask=None, rank=4, xl=None, fp16=True, bf16=None, token=None, repo_id=None, push_to_hub=None, validation_prompt=None, num_validation_images=4, validation_epochs=50, checkpoints_total_limit=None, validation_images=None, logging=None, username=None, func=<function run_dreambooth_command_factory at 0x796ffbb96ef0>)\u001b[0m\n",
            "> \u001b[1mINFO    Running DreamBooth Training\u001b[0m\n",
            "> \u001b[33m\u001b[1mWARNING Parameters supplied but not used: func, version\u001b[0m\n",
            "Downloading (â€¦)okenizer_config.json: 100% 737/737 [00:00<00:00, 3.77MB/s]\n",
            "Downloading (â€¦)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 4.49MB/s]\n",
            "Downloading (â€¦)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 61.6MB/s]\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 2.68MB/s]\n",
            "Downloading (â€¦)okenizer_config.json: 100% 725/725 [00:00<00:00, 3.68MB/s]\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 2.38MB/s]\n",
            "Downloading (â€¦)_encoder/config.json: 100% 565/565 [00:00<00:00, 2.69MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "Downloading (â€¦)ncoder_2/config.json: 100% 575/575 [00:00<00:00, 2.38MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "Downloading model.safetensors: 100% 492M/492M [00:02<00:00, 234MB/s]\n",
            "Downloading model.safetensors: 100% 2.78G/2.78G [00:10<00:00, 255MB/s]\n",
            "Downloading (â€¦)main/vae/config.json: 100% 642/642 [00:00<00:00, 3.49MB/s]\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 335M/335M [00:01<00:00, 298MB/s]\n",
            "Downloading (â€¦)ain/unet/config.json: 100% 1.68k/1.68k [00:00<00:00, 9.28MB/s]\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 10.3G/10.3G [01:00<00:00, 169MB/s] \n",
            "{'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (â€¦)cheduler_config.json: 100% 479/479 [00:00<00:00, 2.00MB/s]\n",
            "{'dynamic_thresholding_ratio', 'thresholding', 'clip_sample_range', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "> \u001b[1mINFO    Enabling xformers\u001b[0m\n",
            "> \u001b[1mINFO    Enabling gradient checkpointing.\u001b[0m\n",
            "> \u001b[1mINFO    Computing text embeddings for prompt: photo of DR\u001b[0m\n",
            "> \u001b[1mINFO    ***** Running training *****\u001b[0m\n",
            "> \u001b[1mINFO      Num examples = 7\u001b[0m\n",
            "> \u001b[1mINFO      Num batches each epoch = 7\u001b[0m\n",
            "> \u001b[1mINFO      Num Epochs = 250\u001b[0m\n",
            "> \u001b[1mINFO      Instantaneous batch size per device = 1\u001b[0m\n",
            "> \u001b[1mINFO      Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "> \u001b[1mINFO      Gradient Accumulation steps = 4\u001b[0m\n",
            "> \u001b[1mINFO      Total optimization steps = 500\u001b[0m\n",
            "> \u001b[1mINFO      Training config = {'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'revision': None, 'tokenizer': None, 'image_path': 'images/', 'class_image_path': None, 'prompt': 'photo of DR', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'my_profile_creater', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 250, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'gradient_checkpointing': True, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': True, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'fp16': True, 'bf16': False, 'token': None, 'repo_id': None, 'push_to_hub': False, 'username': None, 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "Steps:   0% 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/diffusers/models/attention_processor.py:1459: FutureWarning: `LoRAAttnProcessor2_0` is deprecated and will be removed in version 0.26.0. Make sure use AttnProcessor2_0 instead by settingLoRA layers to `self.{to_q,to_k,to_v,to_out[0]}.lora_layer` respectively. This will be done automatically when using `LoraLoaderMixin.load_lora_weights`\n",
            "  deprecate(\n",
            "Steps: 100% 500/500 [1:41:13<00:00, 11.83s/it, loss=0.152, lr=0.0001]Model weights saved in my_profile_creater/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 500/500 [1:41:13<00:00, 12.15s/it, loss=0.152, lr=0.0001]\n"
          ]
        }
      ],
      "source": [
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path images/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "$( [[ \"$USE_FP16\" == \"True\" ]] && echo \"--fp16\" ) \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN} --repo-id ${REPO_ID}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_LvIS7-7PcLT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578,
          "referenced_widgets": [
            "82a746f961f240b7b033d07c3ce18e10",
            "e50cc64629174b11a83efc6f4428b8fc",
            "f66ea6081a444afd910d1eac9ee456dd",
            "6d4772c4ddc343a19393a379bddfc7ea",
            "0c41f88768a748c5ba61de86bf3b1384",
            "3412281ad22249ca89fa9d260bcefe59",
            "991bfd22b42a492889a1b887fe4b339e",
            "a4bc5aaaa32740508065553c99d746ce",
            "a7849776bc9649fa8615582313a5a145",
            "4d08010e22464363a3b75fa1fa099177",
            "317797d97108418ea1031ba523c16760"
          ]
        },
        "outputId": "92a81ed6-9838-4f9c-f40e-8d19b710eb84"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82a746f961f240b7b033d07c3ce18e10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/utils/hub_utils.py\u001b[0m in \u001b[0;36m_get_model_file\u001b[0;34m(pretrained_model_name_or_path, weights_name, subfolder, cache_dir, force_download, proxies, resume_download, local_files_only, use_auth_token, user_agent, revision, commit_hash)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# 2. Load model file as usual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             model_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mREPO_ID_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;34m\"Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: ''.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-93e31464be9f>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_lora_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprj_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pytorch_lora_weights.safetensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/loaders.py\u001b[0m in \u001b[0;36mload_lora_weights\u001b[0;34m(self, pretrained_model_name_or_path_or_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2610\u001b[0m                     \u001b[0mrecursive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_sequential_cpu_offload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2611\u001b[0m                     \u001b[0mremove_hook_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2612\u001b[0;31m         state_dict, network_alphas = self.lora_state_dict(\n\u001b[0m\u001b[1;32m   2613\u001b[0m             \u001b[0mpretrained_model_name_or_path_or_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2614\u001b[0m             \u001b[0munet_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/loaders.py\u001b[0m in \u001b[0;36mlora_state_dict\u001b[0;34m(cls, pretrained_model_name_or_path_or_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                         \u001b[0mpretrained_model_name_or_path_or_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_extension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".bin\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                     )\n\u001b[0;32m-> 1174\u001b[0;31m                 model_file = _get_model_file(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mpretrained_model_name_or_path_or_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mweights_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_name\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mLORA_WEIGHT_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/utils/hub_utils.py\u001b[0m in \u001b[0;36m_get_model_file\u001b[0;34m(pretrained_model_name_or_path, weights_name, subfolder, cache_dir, force_download, proxies, resume_download, local_files_only, use_auth_token, user_agent, revision, commit_hash)\u001b[0m\n\u001b[1;32m    355\u001b[0m             )\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m    358\u001b[0m                 \u001b[0;34mf\"We couldn't connect to '{HUGGINGFACE_CO_RESOLVE_ENDPOINT}' to load this model, couldn't find it\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0;34mf\" in the cached files and it looks like {pretrained_model_name_or_path} is not the path to a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like  is not the path to a directory containing a file named pytorch_lora_weights.safetensors or \nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/diffusers/installation#offline-mode'."
          ]
        }
      ],
      "source": [
        "# Inference\n",
        "# this is the inference code that you can use after you have trained your model\n",
        "# Unhide code below and change prj_path to your repo or local path (e.g. my_dreambooth_project)\n",
        "\n",
        "\n",
        "\n",
        "from diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "import torch\n",
        "\n",
        "prj_path = \"\"\n",
        "model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(prj_path, weight_name=\"pytorch_lora_weights.safetensors\")\n",
        "\n",
        "refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "refiner.to(\"cuda\")\n",
        "\n",
        "prompt = \"Linkedin professional photo of DR\"\n",
        "\n",
        "seed = 42\n",
        "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "image = pipe(prompt=prompt, generator=generator).images[0]\n",
        "image = refiner(prompt=prompt, generator=generator, image=image).images[0]\n",
        "image.save(f\"generated_image.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82a746f961f240b7b033d07c3ce18e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e50cc64629174b11a83efc6f4428b8fc",
              "IPY_MODEL_f66ea6081a444afd910d1eac9ee456dd",
              "IPY_MODEL_6d4772c4ddc343a19393a379bddfc7ea"
            ],
            "layout": "IPY_MODEL_0c41f88768a748c5ba61de86bf3b1384"
          }
        },
        "e50cc64629174b11a83efc6f4428b8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3412281ad22249ca89fa9d260bcefe59",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_991bfd22b42a492889a1b887fe4b339e",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "f66ea6081a444afd910d1eac9ee456dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4bc5aaaa32740508065553c99d746ce",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7849776bc9649fa8615582313a5a145",
            "value": 7
          }
        },
        "6d4772c4ddc343a19393a379bddfc7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d08010e22464363a3b75fa1fa099177",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_317797d97108418ea1031ba523c16760",
            "value": " 7/7 [01:10&lt;00:00,  8.18s/it]"
          }
        },
        "0c41f88768a748c5ba61de86bf3b1384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3412281ad22249ca89fa9d260bcefe59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991bfd22b42a492889a1b887fe4b339e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4bc5aaaa32740508065553c99d746ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7849776bc9649fa8615582313a5a145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d08010e22464363a3b75fa1fa099177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317797d97108418ea1031ba523c16760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}